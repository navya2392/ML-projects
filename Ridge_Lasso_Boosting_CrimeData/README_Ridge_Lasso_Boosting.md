# ğŸ™ï¸ Crime Rate Prediction using Regression, LASSO, and Boosting Models

This project explores various regression techniquesâ€”including linear regression, ridge regression, LASSO, principal component regression (PCR), and gradient boostingâ€”for predicting violent crime rates using the **Communities and Crime** dataset. 

---

## ğŸ“ Dataset Overview

- **Source**: [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Communities+and+Crime)
- **Objective**: Predict violent crime per population across 1994 US communities
- **Features**: Socioeconomic, law enforcement, demographic, and policy-related data (~100+ predictors)

---

## ğŸ§ª Project Workflow

### 1ï¸âƒ£ Data Preparation
- Used first 1495 rows as training set, remaining as test set.
- Removed non-predictive attributes (as documented).
- Handled missing values using imputation techniques.

### 2ï¸âƒ£ Exploratory Analysis
- Visualized correlation matrix to identify strongly correlated features.
- Calculated **Coefficient of Variation (CV)** for each feature.
- Selected top âˆš128 â‰ˆ 11 features with highest CV for closer inspection via scatter and box plots.

### 3ï¸âƒ£ Regression Models

#### ğŸ”¹ Linear Regression
- Fit on training data using least squares
- Computed test error (Mean Squared Error)

#### ğŸ”¹ Ridge Regression
- Used cross-validation to select Î» (regularization strength)
- Fit model and reported test MSE

#### ğŸ”¹ LASSO Regression
- Fit model using cross-validation to select Î»
- Repeated both with:
  - Raw features
  - Standardized features
- Reported test MSE and selected variables

#### ğŸ”¹ Principal Component Regression (PCR)
- Applied PCA on feature set
- Chose number of components (M) via cross-validation
- Fit final model and computed test error

---

## ğŸš€ Gradient Boosting with XGBoost

- Trained **L1-penalized gradient boosting trees**
- Used cross-validation to tune the regularization parameter Î±
- Compared model performance with previous regression approaches

---

## ğŸ“ˆ Results Summary

| Model                  | Regularization / Tuning        | Notes |
|-----------------------|-------------------------------|-------|
| Linear Regression     | None                          | Baseline |
| Ridge Regression      | Î» via CV                      | Regularized |
| LASSO                 | Î» via CV                      | Sparse model |
| PCR                   | M via CV                      | Reduced dimensionality |
| XGBoost (Boosting)    | Î± via CV                      | Nonlinear model |

*(Please refer to notebook for exact numerical results)*

---

## ğŸ› ï¸ Tools & Libraries

- Python 3
- pandas, NumPy
- scikit-learn (LinearRegression, RidgeCV, LassoCV, PCA)
- matplotlib, seaborn
- XGBoost for boosting trees

---

## ğŸ“‚ File Structure

```
Ridge_Lasso_Boosting.ipynb            # Main notebook with all regression models and boosting
README.md                             # Summary of the project (this file)
communities.csv                 # Cleaned and preprocessed dataset (if included)
```

---

## ğŸ“« Contact

Feel free to connect via [LinkedIn](https://www.linkedin.com/in/navya-bhat) if you'd like to learn more or collaborate.
