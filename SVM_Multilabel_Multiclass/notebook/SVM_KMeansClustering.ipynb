{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55369417-c544-40f6-afa5-46471d68e809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV  # Split data and search over C\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler  # Encode labels and standardize features\n",
    "from sklearn.svm import SVC, LinearSVC  # SVM and L1-penalized Linear SVM\n",
    "from sklearn.metrics import accuracy_score, zero_one_loss  # Evaluation metrics\n",
    "\n",
    "from imblearn.over_sampling import SMOTE  # For class imbalance handling\n",
    "from imblearn.pipeline import Pipeline  # To create a pipeline with SMOTE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41425d02-fd24-434e-a1f9-a70d71c61c65",
   "metadata": {},
   "source": [
    "Part 1. Support Vector Machine \n",
    "-\n",
    "1A) Data Loading and Pre-processing\n",
    "-\n",
    "- Step 1: Load Data\n",
    "- Step 2: Split features and multi-label outputs\n",
    "- Step 3: Encode each label into integers. SVC only works with numerical labels. Cannot process strings.\n",
    "- Step 4: 70/30 train test split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96f6609a-ef57-4e10-9abc-b30e7ea26a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7195 entries, 0 to 7194\n",
      "Data columns (total 26 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   MFCCs_ 1  7195 non-null   float64\n",
      " 1   MFCCs_ 2  7195 non-null   float64\n",
      " 2   MFCCs_ 3  7195 non-null   float64\n",
      " 3   MFCCs_ 4  7195 non-null   float64\n",
      " 4   MFCCs_ 5  7195 non-null   float64\n",
      " 5   MFCCs_ 6  7195 non-null   float64\n",
      " 6   MFCCs_ 7  7195 non-null   float64\n",
      " 7   MFCCs_ 8  7195 non-null   float64\n",
      " 8   MFCCs_ 9  7195 non-null   float64\n",
      " 9   MFCCs_10  7195 non-null   float64\n",
      " 10  MFCCs_11  7195 non-null   float64\n",
      " 11  MFCCs_12  7195 non-null   float64\n",
      " 12  MFCCs_13  7195 non-null   float64\n",
      " 13  MFCCs_14  7195 non-null   float64\n",
      " 14  MFCCs_15  7195 non-null   float64\n",
      " 15  MFCCs_16  7195 non-null   float64\n",
      " 16  MFCCs_17  7195 non-null   float64\n",
      " 17  MFCCs_18  7195 non-null   float64\n",
      " 18  MFCCs_19  7195 non-null   float64\n",
      " 19  MFCCs_20  7195 non-null   float64\n",
      " 20  MFCCs_21  7195 non-null   float64\n",
      " 21  MFCCs_22  7195 non-null   float64\n",
      " 22  Family    7195 non-null   object \n",
      " 23  Genus     7195 non-null   object \n",
      " 24  Species   7195 non-null   object \n",
      " 25  RecordID  7195 non-null   int64  \n",
      "dtypes: float64(22), int64(1), object(3)\n",
      "memory usage: 1.4+ MB\n",
      "   MFCCs_ 1  MFCCs_ 2  MFCCs_ 3  MFCCs_ 4  MFCCs_ 5  MFCCs_ 6  ...  MFCCs_21  MFCCs_22           Family      Genus         Species  RecordID\n",
      "0      1.00      0.15     -0.11      0.20      0.32      0.26  ...      0.12      0.01  Leptodactylidae  Adenomera  AdenomeraAndre         1\n",
      "1      1.00      0.17     -0.10      0.27      0.34      0.27  ...      0.08      0.03  Leptodactylidae  Adenomera  AdenomeraAndre         1\n",
      "2      1.00      0.15     -0.08      0.29      0.28      0.19  ...      0.10      0.08  Leptodactylidae  Adenomera  AdenomeraAndre         1\n",
      "3      1.00      0.22      0.12      0.33      0.37      0.36  ...     -0.02      0.02  Leptodactylidae  Adenomera  AdenomeraAndre         1\n",
      "4      1.00      0.09     -0.07      0.31      0.33      0.25  ...      0.11      0.08  Leptodactylidae  Adenomera  AdenomeraAndre         1\n",
      "\n",
      "[5 rows x 26 columns]\n",
      "       MFCCs_ 1  MFCCs_ 2  MFCCs_ 3  MFCCs_ 4  MFCCs_ 5  MFCCs_ 6  ...  MFCCs_18  MFCCs_19  MFCCs_20  MFCCs_21  MFCCs_22  RecordID\n",
      "count   7195.00   7195.00   7195.00   7195.00   7195.00   7195.00  ...   7195.00   7195.00   7195.00   7195.00   7195.00   7195.00\n",
      "mean       0.99      0.32      0.31      0.45      0.13      0.10  ...      0.01     -0.05     -0.05      0.04      0.09     25.22\n",
      "std        0.07      0.22      0.26      0.16      0.16      0.12  ...      0.08      0.08      0.09      0.08      0.12     13.21\n",
      "min       -0.25     -0.67     -0.44     -0.47     -0.64     -0.41  ...     -0.76     -0.68     -0.36     -0.43     -0.38      1.00\n",
      "25%        1.00      0.17      0.14      0.34      0.05      0.01  ...     -0.04     -0.11     -0.12     -0.02      0.00     15.00\n",
      "50%        1.00      0.30      0.27      0.48      0.16      0.07  ...      0.01     -0.05     -0.06      0.03      0.11     22.00\n",
      "75%        1.00      0.47      0.43      0.56      0.22      0.18  ...      0.06      0.01      0.00      0.09      0.19     37.00\n",
      "max        1.00      1.00      1.00      1.00      0.75      0.96  ...      0.61      0.57      0.47      0.39      0.43     60.00\n",
      "\n",
      "[8 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "pd.set_option(\"display.width\", 300)\n",
    "pd.set_option(\"display.max_columns\", 12)\n",
    "pd.set_option(\"display.float_format\", \"{:.2f}\".format)\n",
    "\n",
    "#Step 1: Load Data\n",
    "data = pd.read_csv(\"../data/Anuran Calls (MFCCs)/Frogs_MFCCs.csv\")\n",
    "\n",
    "data.info()\n",
    "print(data.head())\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d270c87-be55-4af8-af47-b449da3c6ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Split features and multi-label outputs\n",
    "X = data.drop(columns=['Family', 'Genus', 'Species', 'RecordID'])  # MFCC features\n",
    "Y = data[['Family', 'Genus', 'Species']].copy()  # Multi-label targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "007e35a3-7bb4-4fb8-bc8a-f1eeb98c4c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Encode each label into integers\n",
    "label_encoders = {}\n",
    "for col in Y.columns:\n",
    "    le = LabelEncoder()\n",
    "    Y[col] = le.fit_transform(Y[col])\n",
    "    label_encoders[col] = le  # Store encoder for inverse transform later\n",
    "\n",
    "# Step 4: 70/30 train/test split with stratify for better label distribution\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42, stratify=Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72505ebb-298d-4068-b9a9-6dc48e315957",
   "metadata": {},
   "source": [
    "1B) Evaluation Metrics\n",
    "--\n",
    "Evaluation Metrics:\n",
    "\n",
    "- Exact Match: A prediction is counted as correct only if all 3 labels match.\n",
    "\n",
    "- Hamming Loss: Fraction of incorrect predictions averaged over all labels.\n",
    "\n",
    "- Hamming Score = 1 - Hamming Loss\n",
    "\n",
    "- - Exact Match is strict (all labels must match); Hamming Score is more lenient and interpretable per-label.\n",
    "\n",
    "\n",
    "Key Considerations:\n",
    "- sklearn.metrics.hamming_loss() doesnâ€™t support multiclass-multioutput. So, I computed loss per label using zero_one_loss and average.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75b07223-f360-45fd-a17f-df6e379a22f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hamming Loss for multiclass multi-label = average of per-label classification error\n",
    "def hamming_loss_multiclass(y_true, y_pred):\n",
    "    losses = [\n",
    "        zero_one_loss(y_true[:, i], y_pred[:, i])\n",
    "        for i in range(y_true.shape[1])\n",
    "    ]\n",
    "    return np.mean(losses)\n",
    "\n",
    "# Hamming Score = 1 - average Hamming Loss\n",
    "def hamming_score(y_true, y_pred):\n",
    "    return 1 - hamming_loss_multiclass(y_true, y_pred)\n",
    "\n",
    "# Exact Match Score\n",
    "def exact_match_score(y_true, y_pred):\n",
    "    return np.mean(np.all(y_true == y_pred, axis=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b1d62a-5af2-4eed-b625-d355146b07a8",
   "metadata": {},
   "source": [
    "1C) SVM Model\n",
    "-\n",
    "\n",
    "Step 1: Coarse Grid Search (Stage 1)\n",
    "- Define a coarse parameter grid: C = [0.1, 1, 10, 100, 1000].  gamma = [0.001, 0.01, 0.1, 1, 10]\n",
    "- Use this grid to explore a wide range of penalty and kernel width values across 10-fold cross-validation.\n",
    "\n",
    "Step 2: Identify Best Parameters for Each Label\n",
    "- Train one SVM per label (Family, Genus, Species) using the coarse grid.\n",
    "- Extract the best C and gamma values per label.\n",
    "- Determine if best values lie at the edges of the coarse grid.\n",
    "\n",
    "Step 3: Refine Grid Search (Stage 2)\n",
    "- If best values lie on the edge, define a refined grid centered around those best values:\n",
    "- coarse best was C=100, gamma=1, use refined grid: C = [50, 100, 200] gamma = [0.5, 1, 2]\n",
    "- Use GridSearchCV again on the refined grid for each label.\n",
    "\n",
    "Step 4: Train Final Models Using Refined Parameters\n",
    "- Fit one SVM per label using best parameters found from refined search.\n",
    "\n",
    "Step 5: Evaluate on Test Set\n",
    "- Predict using the final models on X_test.\n",
    "- Evaluate using:\n",
    "- Exact Match Score\n",
    "- Hamming Loss\n",
    "- Hamming Score = 1 - Hamming Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1efb1bd-1e19-4a82-85ce-d0f586ddabbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Refined Tuning] Training SVM for label: Family\n",
      "Best refined parameters for Family: {'C': 50, 'gamma': 2, 'kernel': 'rbf'}\n",
      "\n",
      "[Refined Tuning] Training SVM for label: Genus\n",
      "Best refined parameters for Genus: {'C': 50, 'gamma': 2, 'kernel': 'rbf'}\n",
      "\n",
      "[Refined Tuning] Training SVM for label: Species\n",
      "Best refined parameters for Species: {'C': 50, 'gamma': 2, 'kernel': 'rbf'}\n",
      "\n",
      "Evaluation Results on Test Set:\n",
      "Exact Match Score: 0.9861046780917091\n",
      "Hamming Loss: 0.00910915547321293\n",
      "Hamming Score: 0.9908908445267871\n"
     ]
    }
   ],
   "source": [
    "pd.set_option(\"display.float_format\", \"{:.2f}\".format)\n",
    "\n",
    "# Coarse Parameter Grid (Stage 1)\n",
    "# Used initially to identify a rough range of hyperparameters for each label\n",
    "coarse_param_grid = {\n",
    "    'C': [0.1, 1, 10, 100, 1000],  # SVM penalty weight (wide range to find boundaries)\n",
    "    'gamma': [0.001, 0.01, 0.1, 1, 10],  # Gaussian kernel width (gamma = 1 / (2 * sigma^2))\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "# Refined Parameter Grid (Stage 2)\n",
    "# Narrowed grid based on coarse tuning results to better pinpoint optimal parameters\n",
    "refined_param_grid = {\n",
    "    'C': [50, 100, 200],  # Refined around the best found C (previously 100)\n",
    "    'gamma': [0.5, 1, 2],  # Refined around the best found gamma (previously 1)\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "# Dictionary to store final models and best parameters per label\n",
    "models = {}\n",
    "best_params = {}\n",
    "\n",
    "# Train one SVM per label using GridSearchCV on refined grid\n",
    "# Each label is treated independently (binary relevance for multi-label)\n",
    "for label in Y.columns:\n",
    "    print(f\"\\n[Refined Tuning] Training SVM for label: {label}\")\n",
    "    # Perform 10-fold cross-validation to select best hyperparameters\n",
    "    grid_search = GridSearchCV(SVC(), refined_param_grid, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train, Y_train[label])\n",
    "    models[label] = grid_search.best_estimator_  # Store best model for current label\n",
    "    best_params[label] = grid_search.best_params_  # Store best parameters\n",
    "    print(f\"Best refined parameters for {label}: {grid_search.best_params_}\")\n",
    "\n",
    "# Evaluate models on test set.\n",
    "# Predict each label independently using corresponding trained SVM\n",
    "Y_pred = np.zeros_like(Y_test)  # Initialize prediction matrix with same shape as Y_test\n",
    "for i, label in enumerate(Y.columns):\n",
    "    Y_pred[:, i] = models[label].predict(X_test)\n",
    "\n",
    "# Compute multi-label evaluation metrics\n",
    "print(\"\\nEvaluation Results on Test Set:\")\n",
    "print(\"Exact Match Score:\", exact_match_score(Y_test.values, Y_pred))\n",
    "print(\"Hamming Loss:\", hamming_loss_multiclass(Y_test.values, Y_pred))\n",
    "print(\"Hamming Score:\", hamming_score(Y_test.values, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357deb7e-d171-4eaf-a3e6-84255802ca78",
   "metadata": {},
   "source": [
    "1D) SVM with L1-Penalized Regression\n",
    "-\n",
    "Steps:\n",
    "Step 1: Standardize the input features using StandardScaler().\n",
    "- This is required for L1-penalized models as LinearSCV\n",
    "- Fit scaler on training data and use it to transform both train and test sets to prevent data leakage.\n",
    "\n",
    "Step 2: Define grid of C values for regularization. \n",
    "\n",
    "Step 3: Train one model per Label with GridSearchCV\n",
    "\n",
    "Step 4: Predict on test set and evaluate Model performance. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ba02718-fa62-4f21-b706-6745fe943c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training L1-Penalized SVM for label: Family\n",
      "Best C for Family: 10\n",
      "\n",
      "Training L1-Penalized SVM for label: Genus\n",
      "Best C for Genus: 10\n",
      "\n",
      "Training L1-Penalized SVM for label: Species\n",
      "Best C for Species: 100\n",
      "\n",
      "Evaluation Results on Test Set (L1-Penalized SVM):\n",
      "Exact Match Score: 0.9143121815655396\n",
      "Hamming Loss: 0.048633626679018084\n",
      "Hamming Score: 0.951366373320982\n"
     ]
    }
   ],
   "source": [
    "pd.set_option(\"display.float_format\", \"{:.2f}\".format)\n",
    "\n",
    "# Step 1: Standardize features \n",
    "scaler = StandardScaler() #Initialize standard scaler \n",
    "X_train = scaler.fit_transform(X_train)  # Fit on train set (Avoid data leakage to test data) \n",
    "X_test = scaler.transform(X_test)        # Transform test set using same scaler. \n",
    "\n",
    "\n",
    "# Step 2: Define penalty weight values for L1-penalized SVM\n",
    "c_values = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "models = {} #Dictionary to store the best model for each label\n",
    "best_params = {} #Dictionary to store the best C for each label\n",
    "\n",
    "# Step 3: Train one LinearSVC per label using GridSearchCV\n",
    "for label in Y.columns:\n",
    "    print(f\"\\nTraining L1-Penalized SVM for label: {label}\")\n",
    "    l1_svc = LinearSVC(penalty='l1', dual=False, max_iter=10000)\n",
    "    param_grid = {'C': c_values}\n",
    "\n",
    "    grid_search = GridSearchCV(l1_svc, param_grid, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train, Y_train[label])\n",
    "\n",
    "    models[label] = grid_search.best_estimator_\n",
    "    best_params[label] = grid_search.best_params_\n",
    "    print(f\"Best C for {label}: {grid_search.best_params_['C']}\")\n",
    "\n",
    "# Step 4: Predict on test set for each label and evaluate model performance. \n",
    "Y_pred = np.zeros_like(Y_test)\n",
    "for i, label in enumerate(Y.columns):\n",
    "    Y_pred[:, i] = models[label].predict(X_test)\n",
    "\n",
    "print(\"\\nEvaluation Results on Test Set (L1-Penalized SVM):\")\n",
    "print(\"Exact Match Score:\", exact_match_score(Y_test.values, Y_pred))\n",
    "print(\"Hamming Loss:\", hamming_loss_multiclass(Y_test.values, Y_pred))\n",
    "print(\"Hamming Score:\", hamming_score(Y_test.values, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabfaecf-f4ff-4ca3-84c6-0dc174fa542b",
   "metadata": {},
   "source": [
    "Findings: Hamming Score is higher for RBF Gaussian Kernel (non-linear) as compared to the linear Kernel\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf15293-2481-49ec-8e60-b612e6158137",
   "metadata": {},
   "source": [
    "1E) SMOTE to address class imbalance\n",
    "-\n",
    "\n",
    "Steps breakdown:\n",
    "\n",
    "Step 1: Define Grid of C values. \n",
    "\n",
    "Step 2: Train with SMOTE + StandardScaler + LinearSVC in a pipeline (using cross-validation). \n",
    "Create a pipeline that performs:\n",
    "\n",
    "- SMOTE to balance class distribution per label\n",
    "\n",
    "- Standardization using StandardScaler\n",
    "\n",
    "- L1-penalized LinearSVC\n",
    "\n",
    "Use GridSearchCV to select the best C via 10-fold CV.\n",
    "\n",
    "Key Considerations:\n",
    "\n",
    "- SMOTE is applied inside each CV fold, avoiding data leakage.\n",
    "\n",
    "- Standardization must happen after SMOTE and within the CV fold.\n",
    "\n",
    "Step 3: Refit the Best Model on Fully SMOTE-Augmented Training Data\n",
    "\n",
    "- After identifying best C, reapply SMOTE to the full training data for each label.\n",
    "\n",
    "- Fit a new LinearSVC using the best C and the resampled (balanced) training set.\n",
    "\n",
    "- Standardize the resampled training data and transform the original test set using the same scaler.\n",
    "\n",
    "- This step ensures that the final model is trained on balanced data. We should not use best_estimator_ directly on unbalanced data â€” always refit.\n",
    "\n",
    "Step 4: Predict and Evaluate on the original test set. \n",
    "- Never apply SMOTE to the test set. Keep it untouched to simulate real-world, imbalanced conditions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f2ff5cf-8ba9-4758-9fd0-073e812be735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SMOTE-enhanced L1-SVM for label: Family\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Best C for Family: 10\n",
      "[LibLinear]\n",
      "Training SMOTE-enhanced L1-SVM for label: Genus\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Best C for Genus: 10\n",
      "[LibLinear]\n",
      "Training SMOTE-enhanced L1-SVM for label: Species\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Best C for Species: 0.1\n",
      "[LibLinear]\n",
      "Evaluation Results on Test Set (L1-SVM with SMOTE):\n",
      "Exact Match Score: 0.8179712830013895\n",
      "Hamming Loss: 0.08692295815964184\n",
      "Hamming Score: 0.9130770418403582\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Define grid of C values for regularization strength\n",
    "c_values = [0.1, 1, 10]  # Reduced grid to speed up training\n",
    "\n",
    "models = {}         # Stores final model for each label\n",
    "best_params = {}    # Stores best C for each label\n",
    "\n",
    "# Step 2: Train with Pipeline(SMOTE + StandardScaler + LinearSVC) using CV for each label. \n",
    "for label in Y.columns:\n",
    "    print(f\"\\nTraining SMOTE-enhanced L1-SVM for label: {label}\")\n",
    "\n",
    "    # Build pipeline\n",
    "    pipe = Pipeline([\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('scaler', StandardScaler()),\n",
    "                # Reduced max_iter to speed up training\n",
    "        ('svc', LinearSVC(penalty='l1', dual=False, max_iter=3000, tol=1e-3, verbose=1))\n",
    "    ])\n",
    "\n",
    "    # Grid search over C values (passed into svc step in pipeline)\n",
    "    param_grid = {\n",
    "        'svc__C': c_values # Double underscore for nested parameter names\n",
    "    }\n",
    "\n",
    "    # Perform 10-fold cross-validation using accuracy as the scoring metric\n",
    "    grid_search = GridSearchCV(pipe, param_grid, cv=10, scoring='accuracy', n_jobs=1)\n",
    "    grid_search.fit(X_train, Y_train[label])\n",
    "\n",
    "    best_C = grid_search.best_params_['svc__C']\n",
    "    best_params[label] = best_C\n",
    "    print(f\"Best C for {label}: {best_C}\")\n",
    "\n",
    "    # Step 3: Fit best model again on full SMOTE-applied training data\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, Y_train[label])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_resampled = scaler.fit_transform(X_resampled)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    final_model = LinearSVC(penalty='l1', dual=False, max_iter=3000, tol=1e-3, verbose=1, C=best_C)\n",
    "    final_model.fit(X_resampled, y_resampled)\n",
    "    models[label] = final_model\n",
    "\n",
    "# Step 4: Predict and evaluate\n",
    "Y_pred = np.zeros_like(Y_test)\n",
    "for i, label in enumerate(Y.columns):\n",
    "    Y_pred[:, i] = models[label].predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nEvaluation Results on Test Set (L1-SVM with SMOTE):\")\n",
    "print(\"Exact Match Score:\", exact_match_score(Y_test.values, Y_pred))\n",
    "print(\"Hamming Loss:\", hamming_loss_multiclass(Y_test.values, Y_pred))\n",
    "print(\"Hamming Score:\", hamming_score(Y_test.values, Y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f182f5b1-a1c6-43e4-bfd3-42b7ed8ff5ca",
   "metadata": {},
   "source": [
    "Part 2) K-Means Clustering\n",
    "-\n",
    "Steps:\n",
    "-\n",
    "\n",
    "Step 1: Use entire Anuran MFCC dataset (no splitting) â€” since this is unsupervised clustering, we donâ€™t do train/test splitting. \n",
    "\n",
    "- Perform encoding as metrics like Hammong loss require numeric input.\n",
    "- Also we need to use functions like np.bincount to compute majority label in each cluster, whcih only work with integer. \n",
    "\n",
    "Step 2: Run Monte Carlo Simulation (50 times)\n",
    "\n",
    "Step 3: For each trial, automatically choose the number of clusters using CH Score. \n",
    "\n",
    "Step 3: Cluster data using K-means with chosen k. Assigns cluster ID to each data point\n",
    "\n",
    "Step 4: Assign majority label with cluster. \n",
    "\n",
    "Step 5:Evaluate clusters and report results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf61a509-50ee-4e49-ba31-05e70f9988c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 1 of 50...\n",
      "Running trial 2 of 50...\n",
      "Running trial 3 of 50...\n",
      "Running trial 4 of 50...\n",
      "Running trial 5 of 50...\n",
      "Running trial 6 of 50...\n",
      "Running trial 7 of 50...\n",
      "Running trial 8 of 50...\n",
      "Running trial 9 of 50...\n",
      "Running trial 10 of 50...\n",
      "Running trial 11 of 50...\n",
      "Running trial 12 of 50...\n",
      "Running trial 13 of 50...\n",
      "Running trial 14 of 50...\n",
      "Running trial 15 of 50...\n",
      "Running trial 16 of 50...\n",
      "Running trial 17 of 50...\n",
      "Running trial 18 of 50...\n",
      "Running trial 19 of 50...\n",
      "Running trial 20 of 50...\n",
      "Running trial 21 of 50...\n",
      "Running trial 22 of 50...\n",
      "Running trial 23 of 50...\n",
      "Running trial 24 of 50...\n",
      "Running trial 25 of 50...\n",
      "Running trial 26 of 50...\n",
      "Running trial 27 of 50...\n",
      "Running trial 28 of 50...\n",
      "Running trial 29 of 50...\n",
      "Running trial 30 of 50...\n",
      "Running trial 31 of 50...\n",
      "Running trial 32 of 50...\n",
      "Running trial 33 of 50...\n",
      "Running trial 34 of 50...\n",
      "Running trial 35 of 50...\n",
      "Running trial 36 of 50...\n",
      "Running trial 37 of 50...\n",
      "Running trial 38 of 50...\n",
      "Running trial 39 of 50...\n",
      "Running trial 40 of 50...\n",
      "Running trial 41 of 50...\n",
      "Running trial 42 of 50...\n",
      "Running trial 43 of 50...\n",
      "Running trial 44 of 50...\n",
      "Running trial 45 of 50...\n",
      "Running trial 46 of 50...\n",
      "Running trial 47 of 50...\n",
      "Running trial 48 of 50...\n",
      "Running trial 49 of 50...\n",
      "Running trial 50 of 50...\n",
      "   Hamming Loss (mean)  Hamming Loss (std)  Hamming Score (mean)  Hamming Score (std)\n",
      "0                 0.30                0.00                  0.70                 0.00\n"
     ]
    }
   ],
   "source": [
    "# Prepare features and labels\n",
    "features = data.drop(columns=[\"Family\", \"Genus\", \"Species\", \"RecordID\"])\n",
    "labels = data[[\"Family\", \"Genus\", \"Species\"]].copy() \n",
    "\n",
    "# Encode labels as metrics like Hammong Loss require numerical values. \n",
    "le_family = LabelEncoder()\n",
    "le_genus = LabelEncoder()\n",
    "le_species = LabelEncoder()\n",
    "labels[\"Family\"] = le_family.fit_transform(labels[\"Family\"])\n",
    "labels[\"Genus\"] = le_genus.fit_transform(labels[\"Genus\"])\n",
    "labels[\"Species\"] = le_species.fit_transform(labels[\"Species\"])\n",
    "\n",
    "Y_true = labels.values #Store encoded labels as a NumPy array for comparison\n",
    "\n",
    "#Initialize lists to store Hamming losses and scores for each trial. \n",
    "hamming_losses = []\n",
    "hamming_scores = []\n",
    "num_trials = 50 # Number of Monte Carlo Trials\n",
    "max_k = 20 #Max number of clusters to consider. \n",
    "\n",
    "for trial in range(num_trials):\n",
    "    print(f\"Running trial {trial + 1} of {num_trials}...\") #Track progress \n",
    "    ch_scores = [] #Store CH index scores for different values of k. \n",
    "\n",
    "    #Try different values of k from 2 to max_k to find the best_k\n",
    "    for i in range(2, max_k + 1):  # CH index requires at least 2 clusters\n",
    "        kmeans = KMeans(n_clusters=i, n_init=10, random_state=None) \n",
    "        clusters = kmeans.fit_predict(features) #Assign clusters. \n",
    "        score = calinski_harabasz_score(features, clusters) #Compute CH score\n",
    "        ch_scores.append(score) #save score \n",
    "\n",
    "    #Get k with max CH sccore. offset by 2 because we started at k = 2. \n",
    "    best_k = np.argmax(ch_scores) + 2  \n",
    "\n",
    "    #Run K-means again with best number of clustesr. \n",
    "    kmeans = KMeans(n_clusters=best_k, n_init=10, random_state=None)\n",
    "    clusters = kmeans.fit_predict(features) #Assign clusters to each data point. \n",
    "\n",
    "    # Assign majority label for each cluster for each of the 3 labels. \n",
    "    Y_pred = np.zeros_like(Y_true)\n",
    "    for cluster_id in range(best_k):\n",
    "        idx = np.where(clusters == cluster_id)[0] #Find indices of points in this cluster. \n",
    "        for i in range(3):\n",
    "            if len(idx) == 0:\n",
    "                continue #Skip empty clusters\n",
    "            majority_label = np.bincount(Y_true[idx, i]).argmax() #Most common label \n",
    "            Y_pred[idx, i] = majority_label #Assign majority label to all points in this cluster. \n",
    "\n",
    "    ## Compute average Hamming loss across the 3 labels\n",
    "    losses = [hamming_loss(Y_true[:, i], Y_pred[:, i]) for i in range(3)] #Per label Hamming loss\n",
    "    hamming_losses.append(np.mean(losses)) #mean loss\n",
    "\n",
    "    # Compute average Hamming score (correct predictions / total labels)\n",
    "    correct = np.sum(Y_true == Y_pred, axis=1)  # Number of correct labels per instance\n",
    "    score = np.mean(correct / Y_true.shape[1]) # Average score across instances\n",
    "    hamming_scores.append(score) # Store Hamming score\n",
    "\n",
    "# After all trials, compute mean and std for Hamming loss and score\n",
    "mean_loss = np.mean(hamming_losses)  # Mean Hamming loss over trials\n",
    "std_loss = np.std(hamming_losses)    # Std deviation of Hamming loss\n",
    "mean_score = np.mean(hamming_scores) # Mean Hamming score\n",
    "std_score = np.std(hamming_scores)   # Std deviation of Hamming score\n",
    "\n",
    "# Store results in a DataFrame for display\n",
    "results = pd.DataFrame({\n",
    "    \"Hamming Loss (mean)\": [mean_loss],\n",
    "    \"Hamming Loss (std)\": [std_loss],\n",
    "    \"Hamming Score (mean)\": [mean_score],\n",
    "    \"Hamming Score (std)\": [std_score]\n",
    "})\n",
    "# Display the result\n",
    "print(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e090304-5d93-42d5-b82c-c035e60a1986",
   "metadata": {},
   "source": [
    "Source:\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC\n",
    "-\thttps://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "-\thttps://scikit-learn.org/stable/modules/grid_search.html\n",
    "-\thttps://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html\n",
    "-\thttps://medium.com/data-science/the-right-way-of-using-smote-with-cross-validation-92a8d09d00c7\n",
    "-\thttps://stats.stackexchange.com/questions/417576/can-we-apply-smote-on-data-with-k-fold-cv\n",
    "-\thttps://www.kaggle.com/discussions/questions-and-answers/427399\n",
    "-\thttps://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "-\thttps://medium.com/@whystudying/monte-carlo-simulation-with-python-13e09731d500\n",
    "-\thttps://scikit-learn.org/stable/modules/generated/sklearn.metrics.calinski_harabasz_score.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17b1291-b92a-413f-a2e1-72de5c05f3a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
